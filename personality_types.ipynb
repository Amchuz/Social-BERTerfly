{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "personality_analysis",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEQqrjozIFOO"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "data = pd.read_csv(\"dataset/mbti_1.csv\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8ZNYhAsJGvu",
        "outputId": "4b81943a-e6dc-4bc8-9a18-1ebb97fae92b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "source": [
        "data.head(16)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "      <th>type_index</th>\n",
              "      <th>cleaned_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
              "      <td>8</td>\n",
              "      <td>enfp  and  intj  moments  sportscenter  not  t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENTP</td>\n",
              "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
              "      <td>3</td>\n",
              "      <td>im  finding  the  lack  of  me  in  these  pos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>INTP</td>\n",
              "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
              "      <td>11</td>\n",
              "      <td>good  one    of  course  to  which  i  say  i ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>INTJ</td>\n",
              "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
              "      <td>10</td>\n",
              "      <td>dear  intp  i  enjoyed  our  conversation  the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENTJ</td>\n",
              "      <td>'You're fired.|||That's another silly misconce...</td>\n",
              "      <td>2</td>\n",
              "      <td>youre  fired  thats  another  silly  misconcep...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>INTJ</td>\n",
              "      <td>'18/37 @.@|||Science  is not perfect. No scien...</td>\n",
              "      <td>10</td>\n",
              "      <td>1837    science  is  not  perfect  no  scienti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>'No, I can't draw on my own nails (haha). Thos...</td>\n",
              "      <td>8</td>\n",
              "      <td>no  i  cant  draw  on  my  own  nails  haha  t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>INTJ</td>\n",
              "      <td>'I tend to build up a collection of things on ...</td>\n",
              "      <td>10</td>\n",
              "      <td>i  tend  to  build  up  a  collection  of  thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>I'm not sure, that's a good question. The dist...</td>\n",
              "      <td>8</td>\n",
              "      <td>im  not  sure  thats  a  good  question  the  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>INTP</td>\n",
              "      <td>'https://www.youtube.com/watch?v=w8-egj0y8Qs||...</td>\n",
              "      <td>11</td>\n",
              "      <td>im  in  this  position  where  i  have  to  ac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>'One time my parents were fighting over my dad...</td>\n",
              "      <td>8</td>\n",
              "      <td>one  time  my  parents  were  fighting  over  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>ENFJ</td>\n",
              "      <td>'https://www.youtube.com/watch?v=PLAaiKvHvZs||...</td>\n",
              "      <td>0</td>\n",
              "      <td>51  o  i  went  through  a  break  up  some  m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>'Joe santagato - ENTP|||ENFJ or  ENTP?   I'm n...</td>\n",
              "      <td>8</td>\n",
              "      <td>joe  santagato    entp  enfj  or  entp  im  no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>INTJ</td>\n",
              "      <td>'Fair enough, if that's how you want to look a...</td>\n",
              "      <td>10</td>\n",
              "      <td>fair  enough  if  thats  how  you  want  to  l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>INTP</td>\n",
              "      <td>'Basically this...  https://youtu.be/1pH5c1Jkh...</td>\n",
              "      <td>11</td>\n",
              "      <td>basically  this  can  i  has  cheezburgr  i  a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>INTP</td>\n",
              "      <td>'Your comment screams INTJ, bro. Especially th...</td>\n",
              "      <td>11</td>\n",
              "      <td>your  comment  screams  intj  bro  especially ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    type  ...                                       cleaned_text\n",
              "0   INFJ  ...  enfp  and  intj  moments  sportscenter  not  t...\n",
              "1   ENTP  ...  im  finding  the  lack  of  me  in  these  pos...\n",
              "2   INTP  ...  good  one    of  course  to  which  i  say  i ...\n",
              "3   INTJ  ...  dear  intp  i  enjoyed  our  conversation  the...\n",
              "4   ENTJ  ...  youre  fired  thats  another  silly  misconcep...\n",
              "5   INTJ  ...  1837    science  is  not  perfect  no  scienti...\n",
              "6   INFJ  ...  no  i  cant  draw  on  my  own  nails  haha  t...\n",
              "7   INTJ  ...  i  tend  to  build  up  a  collection  of  thi...\n",
              "8   INFJ  ...  im  not  sure  thats  a  good  question  the  ...\n",
              "9   INTP  ...  im  in  this  position  where  i  have  to  ac...\n",
              "10  INFJ  ...  one  time  my  parents  were  fighting  over  ...\n",
              "11  ENFJ  ...  51  o  i  went  through  a  break  up  some  m...\n",
              "12  INFJ  ...  joe  santagato    entp  enfj  or  entp  im  no...\n",
              "13  INTJ  ...  fair  enough  if  thats  how  you  want  to  l...\n",
              "14  INTP  ...  basically  this  can  i  has  cheezburgr  i  a...\n",
              "15  INTP  ...  your  comment  screams  intj  bro  especially ...\n",
              "\n",
              "[16 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPAbwV_wMULM"
      },
      "source": [
        "types = np.unique(data.type.values)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxO7gtOsNFqg"
      },
      "source": [
        "def get_type_index(string):\n",
        "    return list(types).index(string)\n",
        "data['type_index'] = data['type'].apply(get_type_index)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kM3aVjQNJsT",
        "outputId": "9d27e900-d23a-4fb7-d99f-d7ff1f2cb0bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "data.posts.values[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"'http://www.youtube.com/watch?v=qsXHcwe3krw|||http://41.media.tumblr.com/tumblr_lfouy03PMA1qa1rooo1_500.jpg|||enfp and intj moments  https://www.youtube.com/watch?v=iz7lE1g4XM4  sportscenter not top ten plays  https://www.youtube.com/watch?v=uCdfze1etec  pranks|||What has been the most life-changing experience in your life?|||http://www.youtube.com/watch?v=vXZeYwwRDw8   http://www.youtube.com/watch?v=u8ejam5DP3E  On repeat for most of today.|||May the PerC Experience immerse you.|||The last thing my INFJ friend posted on his facebook before committing suicide the next day. Rest in peace~   http://vimeo.com/22842206|||Hello ENFJ7. Sorry to hear of your distress. It's only natural for a relationship to not be perfection all the time in every moment of existence. Try to figure the hard times as times of growth, as...|||84389  84390  http://wallpaperpassion.com/upload/23700/friendship-boy-and-girl-wallpaper.jpg  http://assets.dornob.com/wp-content/uploads/2010/04/round-home-design.jpg ...|||Welcome and stuff.|||http://playeressence.com/wp-content/uploads/2013/08/RED-red-the-pokemon-master-32560474-450-338.jpg  Game. Set. Match.|||Prozac, wellbrutin, at least thirty minutes of moving your legs (and I don't mean moving them while sitting in your same desk chair), weed in moderation (maybe try edibles as a healthier alternative...|||Basically come up with three items you've determined that each type (or whichever types you want to do) would more than likely use, given each types' cognitive functions and whatnot, when left by...|||All things in moderation.  Sims is indeed a video game, and a good one at that. Note: a good one at that is somewhat subjective in that I am not completely promoting the death of any given Sim...|||Dear ENFP:  What were your favorite video games growing up and what are your now, current favorite video games? :cool:|||https://www.youtube.com/watch?v=QyPqT8umzmY|||It appears to be too late. :sad:|||There's someone out there for everyone.|||Wait... I thought confidence was a good thing.|||I just cherish the time of solitude b/c i revel within my inner world more whereas most other time i'd be workin... just enjoy the me time while you can. Don't worry, people will always be around to...|||Yo entp ladies... if you're into a complimentary personality,well, hey.|||... when your main social outlet is xbox live conversations and even then you verbally fatigue quickly.|||http://www.youtube.com/watch?v=gDhy7rdfm14  I really dig the part from 1:46 to 2:50|||http://www.youtube.com/watch?v=msqXffgh7b8|||Banned because this thread requires it of me.|||Get high in backyard, roast and eat marshmellows in backyard while conversing over something intellectual, followed by massages and kisses.|||http://www.youtube.com/watch?v=Mw7eoU3BMbE|||http://www.youtube.com/watch?v=4V2uYORhQOk|||http://www.youtube.com/watch?v=SlVmgFQQ0TI|||Banned for too many b's in that sentence. How could you! Think of the B!|||Banned for watching movies in the corner with the dunces.|||Banned because Health class clearly taught you nothing about peer pressure.|||Banned for a whole host of reasons!|||http://www.youtube.com/watch?v=IRcrv41hgz4|||1) Two baby deer on left and right munching on a beetle in the middle.  2) Using their own blood, two cavemen diary today's latest happenings on their designated cave diary wall.  3) I see it as...|||a pokemon world  an infj society  everyone becomes an optimist|||49142|||http://www.youtube.com/watch?v=ZRCEq_JFeFM|||http://discovermagazine.com/2012/jul-aug/20-things-you-didnt-know-about-deserts/desert.jpg|||http://oyster.ignimgs.com/mediawiki/apis.ign.com/pokemon-silver-version/d/dd/Ditto.gif|||http://www.serebii.net/potw-dp/Scizor.jpg|||Not all artists are artists because they draw. It's the idea that counts in forming something of your own... like a signature.|||Welcome to the robot ranks, person who downed my self-esteem cuz I'm not an avid signature artist like herself. :proud:|||Banned for taking all the room under my bed. Ya gotta learn to share with the roaches.|||http://www.youtube.com/watch?v=w8IgImn57aQ|||Banned for being too much of a thundering, grumbling kind of storm... yep.|||Ahh... old high school music I haven't heard in ages.   http://www.youtube.com/watch?v=dcCRUPCdB1w|||I failed a public speaking class a few years ago and I've sort of learned what I could do better were I to be in that position again. A big part of my failure was just overloading myself with too...|||I like this person's mentality. He's a confirmed INTJ by the way. http://www.youtube.com/watch?v=hGKLI-GEc6M|||Move to the Denver area and start a new life for myself.'\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wMgiWagNNFZ"
      },
      "source": [
        "import string\n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    regex = re.compile('[%s]' % re.escape('|'))\n",
        "    text = regex.sub(\" \", text)\n",
        "    words = str(text).split()\n",
        "    words = [i.lower() + \" \" for i in words]\n",
        "    words = [i for i in words if not \"http\" in i]\n",
        "    words = \" \".join(words)\n",
        "    words = words.translate(words.maketrans('', '', string.punctuation))\n",
        "    return words"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH6wx4O9NQzz"
      },
      "source": [
        "data['cleaned_text'] = data['posts'].apply(clean_text)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QcsPmmZNSsg",
        "outputId": "730e30b1-cf51-4925-b2b0-afee146d9983",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "data.cleaned_text.values[0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'enfp  and  intj  moments  sportscenter  not  top  ten  plays  pranks  what  has  been  the  most  lifechanging  experience  in  your  life  on  repeat  for  most  of  today  may  the  perc  experience  immerse  you  the  last  thing  my  infj  friend  posted  on  his  facebook  before  committing  suicide  the  next  day  rest  in  peace  hello  enfj7  sorry  to  hear  of  your  distress  its  only  natural  for  a  relationship  to  not  be  perfection  all  the  time  in  every  moment  of  existence  try  to  figure  the  hard  times  as  times  of  growth  as  84389  84390    welcome  and  stuff  game  set  match  prozac  wellbrutin  at  least  thirty  minutes  of  moving  your  legs  and  i  dont  mean  moving  them  while  sitting  in  your  same  desk  chair  weed  in  moderation  maybe  try  edibles  as  a  healthier  alternative  basically  come  up  with  three  items  youve  determined  that  each  type  or  whichever  types  you  want  to  do  would  more  than  likely  use  given  each  types  cognitive  functions  and  whatnot  when  left  by  all  things  in  moderation  sims  is  indeed  a  video  game  and  a  good  one  at  that  note  a  good  one  at  that  is  somewhat  subjective  in  that  i  am  not  completely  promoting  the  death  of  any  given  sim  dear  enfp  what  were  your  favorite  video  games  growing  up  and  what  are  your  now  current  favorite  video  games  cool  it  appears  to  be  too  late  sad  theres  someone  out  there  for  everyone  wait  i  thought  confidence  was  a  good  thing  i  just  cherish  the  time  of  solitude  bc  i  revel  within  my  inner  world  more  whereas  most  other  time  id  be  workin  just  enjoy  the  me  time  while  you  can  dont  worry  people  will  always  be  around  to  yo  entp  ladies  if  youre  into  a  complimentary  personalitywell  hey    when  your  main  social  outlet  is  xbox  live  conversations  and  even  then  you  verbally  fatigue  quickly  i  really  dig  the  part  from  146  to  250  banned  because  this  thread  requires  it  of  me  get  high  in  backyard  roast  and  eat  marshmellows  in  backyard  while  conversing  over  something  intellectual  followed  by  massages  and  kisses  banned  for  too  many  bs  in  that  sentence  how  could  you  think  of  the  b  banned  for  watching  movies  in  the  corner  with  the  dunces  banned  because  health  class  clearly  taught  you  nothing  about  peer  pressure  banned  for  a  whole  host  of  reasons  1  two  baby  deer  on  left  and  right  munching  on  a  beetle  in  the  middle  2  using  their  own  blood  two  cavemen  diary  todays  latest  happenings  on  their  designated  cave  diary  wall  3  i  see  it  as  a  pokemon  world  an  infj  society  everyone  becomes  an  optimist  49142  not  all  artists  are  artists  because  they  draw  its  the  idea  that  counts  in  forming  something  of  your  own  like  a  signature  welcome  to  the  robot  ranks  person  who  downed  my  selfesteem  cuz  im  not  an  avid  signature  artist  like  herself  proud  banned  for  taking  all  the  room  under  my  bed  ya  gotta  learn  to  share  with  the  roaches  banned  for  being  too  much  of  a  thundering  grumbling  kind  of  storm  yep  ahh  old  high  school  music  i  havent  heard  in  ages  i  failed  a  public  speaking  class  a  few  years  ago  and  ive  sort  of  learned  what  i  could  do  better  were  i  to  be  in  that  position  again  a  big  part  of  my  failure  was  just  overloading  myself  with  too  i  like  this  persons  mentality  hes  a  confirmed  intj  by  the  way  move  to  the  denver  area  and  start  a  new  life  for  myself '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvsL6L9yNV3r"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(data)\n",
        "train, val = train_test_split(train)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arU9jhwp3MxF",
        "outputId": "0a8215f1-55bf-4323-a4c1-e2d46481a639",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print (train.shape)\n",
        "print (val.shape)\n",
        "print (test.shape)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4879, 4)\n",
            "(1627, 4)\n",
            "(2169, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ypaVavSNbP-",
        "outputId": "af0d4e2a-2665-4d35-9873-319bfc228962",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 3.5MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 13.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting tokenizers==0.9.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 23.6MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 47.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=3312a3bc5115c62e754b8ae810e3a9faf7ed9b4e6b14a67db4692251b263abd0\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.9.2 transformers-3.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vejsz3HbNjNa"
      },
      "source": [
        "import transformers\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained('bert-large-uncased')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ON3v_358NvZL"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Flatten, Dropout, Conv1D, GlobalMaxPooling1D\n",
        "\n",
        "def create_model():\n",
        "    op = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size, 256, input_length=maxlen-1))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Bidirectional(LSTM(200, return_sequences=True)))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Bidirectional(LSTM(20)))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(16, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=op, metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG4nOZ9XPKor"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "vocab_size = 10000\n",
        "trunc_type = \"post\"\n",
        "pad_type = \"post\"\n",
        "oov_tok = \"<OOV>\"\n",
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(data.cleaned_text.values)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrWQfyY_NhJw"
      },
      "source": [
        "maxlen = 1500\n",
        "train_sequences = tokenizer.texts_to_sequences(train.cleaned_text.values)\n",
        "train_padded = pad_sequences(train_sequences, maxlen = maxlen, truncating = trunc_type, padding = pad_type)\n",
        "\n",
        "val_sequences = tokenizer.texts_to_sequences(val.cleaned_text.values)\n",
        "val_padded = pad_sequences(val_sequences, maxlen = maxlen, truncating = trunc_type, padding = pad_type)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RskUoy03U_6",
        "outputId": "7fb62254-8391-47a4-bde5-3dd1f73eabc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print (train_padded.shape)\n",
        "print (val_padded.shape)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4879, 1500)\n",
            "(1627, 1500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vI170zWhN2LB",
        "outputId": "6e0e24a0-8f32-46bf-bb7e-0e2261504e96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "use_tpu = False\n",
        "if use_tpu:\n",
        "    # Create distribution strategy\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "    # Create model\n",
        "    with strategy.scope():\n",
        "        model = create_model()\n",
        "else:\n",
        "    model = create_model()\n",
        "    \n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 1499, 256)         2560000   \n",
            "_________________________________________________________________\n",
            "dropout_146 (Dropout)        (None, 1499, 256)         0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 1499, 400)         731200    \n",
            "_________________________________________________________________\n",
            "dropout_147 (Dropout)        (None, 1499, 400)         0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 40)                67360     \n",
            "_________________________________________________________________\n",
            "dropout_148 (Dropout)        (None, 40)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                2624      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 16)                1040      \n",
            "=================================================================\n",
            "Total params: 3,362,224\n",
            "Trainable params: 3,362,224\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO2PIRQ4VKIl"
      },
      "source": [
        "one_hot_labels = tf.keras.utils.to_categorical(train.type_index.values, num_classes=16)\n",
        "val_labels= tf.keras.utils.to_categorical(val.type_index.values, num_classes=16)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRbHqytY3Bey",
        "outputId": "f3dbb1e8-486c-49b0-b547-348d747c7ee2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "one_hot_labels"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWFpvc4GN6ac",
        "outputId": "4e21cd78-7341-46c0-fe47-78364867b2c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(train_padded, one_hot_labels, epochs =20, verbose = 1, \n",
        "          validation_data = (val_padded, val_labels),  callbacks = [tf.keras.callbacks.EarlyStopping(patience = 3)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 1499) for input Tensor(\"embedding_input:0\", shape=(None, 1499), dtype=float32), but it was called on an input with incompatible shape (None, 1500).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 1499) for input Tensor(\"embedding_input:0\", shape=(None, 1499), dtype=float32), but it was called on an input with incompatible shape (None, 1500).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 1499) for input Tensor(\"embedding_input:0\", shape=(None, 1499), dtype=float32), but it was called on an input with incompatible shape (None, 1500).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 1499) for input Tensor(\"embedding_input:0\", shape=(None, 1499), dtype=float32), but it was called on an input with incompatible shape (None, 1500).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  2/153 [..............................] - ETA: 2:51 - loss: 2.7706 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 2.2603s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 2.2603s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "153/153 [==============================] - ETA: 0s - loss: 2.7562 - accuracy: 0.1209WARNING:tensorflow:Model was constructed with shape (None, 1499) for input Tensor(\"embedding_input:0\", shape=(None, 1499), dtype=float32), but it was called on an input with incompatible shape (None, 1500).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 1499) for input Tensor(\"embedding_input:0\", shape=(None, 1499), dtype=float32), but it was called on an input with incompatible shape (None, 1500).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_test_batch_end` time: 0.7025s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_test_batch_end` time: 0.7025s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r153/153 [==============================] - 377s 2s/step - loss: 2.7562 - accuracy: 0.1209 - val_loss: 2.7320 - val_accuracy: 0.1309\n",
            "Epoch 2/20\n",
            "153/153 [==============================] - 378s 2s/step - loss: 2.7045 - accuracy: 0.1301 - val_loss: 2.6568 - val_accuracy: 0.1266\n",
            "Epoch 3/20\n",
            "153/153 [==============================] - 382s 2s/step - loss: 2.6159 - accuracy: 0.1289 - val_loss: 2.5366 - val_accuracy: 0.1266\n",
            "Epoch 4/20\n",
            "153/153 [==============================] - 383s 3s/step - loss: 2.5340 - accuracy: 0.1287 - val_loss: 2.4307 - val_accuracy: 0.1266\n",
            "Epoch 5/20\n",
            "153/153 [==============================] - 384s 3s/step - loss: 2.4562 - accuracy: 0.1685 - val_loss: 2.3695 - val_accuracy: 0.2090\n",
            "Epoch 6/20\n",
            "153/153 [==============================] - 387s 3s/step - loss: 2.4191 - accuracy: 0.1781 - val_loss: 2.3453 - val_accuracy: 0.2090\n",
            "Epoch 7/20\n",
            "153/153 [==============================] - 386s 3s/step - loss: 2.3962 - accuracy: 0.1841 - val_loss: 2.3307 - val_accuracy: 0.2090\n",
            "Epoch 8/20\n",
            "153/153 [==============================] - 386s 3s/step - loss: 2.3919 - accuracy: 0.1836 - val_loss: 2.3209 - val_accuracy: 0.2090\n",
            "Epoch 9/20\n",
            "153/153 [==============================] - 385s 3s/step - loss: 2.3825 - accuracy: 0.1802 - val_loss: 2.3127 - val_accuracy: 0.2090\n",
            "Epoch 10/20\n",
            "153/153 [==============================] - 388s 3s/step - loss: 2.3717 - accuracy: 0.1910 - val_loss: 2.3063 - val_accuracy: 0.2090\n",
            "Epoch 11/20\n",
            "153/153 [==============================] - 388s 3s/step - loss: 2.3660 - accuracy: 0.1830 - val_loss: 2.3019 - val_accuracy: 0.2090\n",
            "Epoch 12/20\n",
            "153/153 [==============================] - 389s 3s/step - loss: 2.3638 - accuracy: 0.1843 - val_loss: 2.2973 - val_accuracy: 0.2090\n",
            "Epoch 13/20\n",
            "153/153 [==============================] - 388s 3s/step - loss: 2.3551 - accuracy: 0.1859 - val_loss: 2.2935 - val_accuracy: 0.2090\n",
            "Epoch 14/20\n",
            "153/153 [==============================] - 389s 3s/step - loss: 2.3582 - accuracy: 0.1927 - val_loss: 2.2903 - val_accuracy: 0.2090\n",
            "Epoch 15/20\n",
            "153/153 [==============================] - 389s 3s/step - loss: 2.3490 - accuracy: 0.1898 - val_loss: 2.2874 - val_accuracy: 0.2090\n",
            "Epoch 16/20\n",
            "153/153 [==============================] - 388s 3s/step - loss: 2.3518 - accuracy: 0.1904 - val_loss: 2.2848 - val_accuracy: 0.2090\n",
            "Epoch 17/20\n",
            "153/153 [==============================] - 389s 3s/step - loss: 2.3518 - accuracy: 0.1810 - val_loss: 2.2834 - val_accuracy: 0.2090\n",
            "Epoch 18/20\n",
            "153/153 [==============================] - 388s 3s/step - loss: 2.3434 - accuracy: 0.1908 - val_loss: 2.2808 - val_accuracy: 0.2090\n",
            "Epoch 19/20\n",
            "153/153 [==============================] - 388s 3s/step - loss: 2.3434 - accuracy: 0.1871 - val_loss: 2.2790 - val_accuracy: 0.2090\n",
            "Epoch 20/20\n",
            "153/153 [==============================] - 389s 3s/step - loss: 2.3383 - accuracy: 0.1896 - val_loss: 2.2773 - val_accuracy: 0.2090\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb7499446a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_w8GLlGU--7"
      },
      "source": [
        "model.save(\"models/personality_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZE73jKM-g-0T",
        "outputId": "8ed0b22f-768e-42c8-ea99-4a2af6cabb9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "new_model = tf.keras.models.load_model('models/personality_model.h5')\n",
        "\n",
        "# Check its architecture\n",
        "new_model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 1499, 256)         2560000   \n",
            "_________________________________________________________________\n",
            "dropout_146 (Dropout)        (None, 1499, 256)         0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 1499, 400)         731200    \n",
            "_________________________________________________________________\n",
            "dropout_147 (Dropout)        (None, 1499, 400)         0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 40)                67360     \n",
            "_________________________________________________________________\n",
            "dropout_148 (Dropout)        (None, 40)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                2624      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 16)                1040      \n",
            "=================================================================\n",
            "Total params: 3,362,224\n",
            "Trainable params: 3,362,224\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-53QKaxmqUZ0"
      },
      "source": [
        "test_labels= tf.keras.utils.to_categorical(test.type_index.values, num_classes=16)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6UzBhcyutni"
      },
      "source": [
        "test_sequences = tokenizer.texts_to_sequences(test.cleaned_text.values)\n",
        "test_padded = pad_sequences(test_sequences, maxlen = 1500, truncating = trunc_type, padding = pad_type)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMRmiIRFrCt4",
        "outputId": "0e148254-2695-4323-d9ec-aa43e01259dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "new_model.evaluate(np.array(test_padded), test_labels)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 1499) for input Tensor(\"embedding_input:0\", shape=(None, 1499), dtype=float32), but it was called on an input with incompatible shape (None, 1500).\n",
            "68/68 [==============================] - 203s 3s/step - loss: 2.2858 - accuracy: 0.2112\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.2857666015625, 0.21115721762180328]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Melw7KJYusgS",
        "outputId": "e0a875cf-7001-48cd-b4af-785dffdfad83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(new_model.predict(test_padded))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 1499) for input Tensor(\"embedding_input:0\", shape=(None, 1499), dtype=float32), but it was called on an input with incompatible shape (None, 1500).\n",
            "[[0.01755055 0.0746889  0.03881089 ... 0.02421712 0.03078783 0.04636303]\n",
            " [0.01594081 0.07214715 0.03871734 ... 0.02321349 0.02850211 0.04422106]\n",
            " [0.01591561 0.07223146 0.03868169 ... 0.02324132 0.02850406 0.04427687]\n",
            " ...\n",
            " [0.01594858 0.07234409 0.03864701 ... 0.02324031 0.02856634 0.0442911 ]\n",
            " [0.01590267 0.07214415 0.03858009 ... 0.02319117 0.02843972 0.04423463]\n",
            " [0.01759198 0.07485618 0.03879917 ... 0.02430656 0.03092699 0.04642294]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa2EnuihtrML",
        "outputId": "b881dfa1-1aa9-45e2-aa4e-f82a057e5399",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "input_text = \"enfp and intj moments  https://www.youtube.com/watch?v=iz7lE1g4XM4  sportscenter not top ten plays  https://www.youtube.com/watch?v=uCdfze1etec  pranks\"\n",
        "cleaned_ip = clean_text(input_text)\n",
        "list_input = []\n",
        "list_input.append(input_text)\n",
        "custom_test_sequences = tokenizer.texts_to_sequences(list_input)\n",
        "print (custom_test_sequences)\n",
        "custom_test_padded = pad_sequences(custom_test_sequences, maxlen = maxlen, truncating = trunc_type, padding = pad_type)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[190, 6, 139, 1305, 1, 1, 916, 1, 487, 2763, 1, 1, 23, 704, 1856, 2079, 1, 1, 916, 1, 487, 2763, 1, 9953]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHlOuwcYxtgL",
        "outputId": "7c7246df-ba6a-4f5c-c2af-ccd8a8547bf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print (custom_test_padded.shape)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 1500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEgq62-sxXYI",
        "outputId": "0f9a0225-fb2f-4b8c-9dce-ab758e2278cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "type_person = np.argmax(new_model.predict(custom_test_padded))\n",
        "print (data[data[\"type_index\"]==type_person][\"type\"].head(1))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17    INFP\n",
            "Name: type, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eu781MVr4_XA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}